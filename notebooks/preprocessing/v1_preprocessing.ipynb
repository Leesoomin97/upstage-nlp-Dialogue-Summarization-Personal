{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4919e30a-295f-45bb-a237-84be5b126229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT ROOT: /root/nlp\n",
      "RAW DIR: /root/nlp/data/raw\n",
      "PROCESSED DIR: /root/nlp/data/processed\n",
      "\n",
      "Loading raw CSV...\n",
      "\n",
      "Processing TRAIN...\n",
      "Processing TEST...\n",
      "\n",
      "SAVED:\n",
      "/root/nlp/data/processed/v1_train_preprocessed.csv\n",
      "/root/nlp/data/processed/v1_test_preprocessed.csv\n",
      "\n",
      "DONE.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ============================================================\n",
    "# 0. PATH (대장 프로젝트 전용 — 단순 & 안정)\n",
    "# ============================================================\n",
    "PROJECT_ROOT = Path.cwd().parents[1]\n",
    "RAW_DIR = PROJECT_ROOT / \"data\" / \"raw\"\n",
    "PROCESSED_DIR = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "PROCESSED_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"PROJECT ROOT:\", PROJECT_ROOT)\n",
    "print(\"RAW DIR:\", RAW_DIR)\n",
    "print(\"PROCESSED DIR:\", PROCESSED_DIR)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Dialogue Preprocessor — v1A (ROUGE 최적화 버전)\n",
    "# ============================================================\n",
    "class DialoguePreprocessor:\n",
    "    def __init__(self):\n",
    "\n",
    "        # title normalization은 유지 (해가 되지 않음)\n",
    "        self.title_map = {\n",
    "            r'\\bDr\\.?\\b': '<Doctor>',\n",
    "            r'\\bMr\\.?\\b': '<Male>',\n",
    "            r'\\bMrs\\.?\\b': '<MarriedFemale>',\n",
    "            r'\\bMs\\.?\\b': '<Female>',\n",
    "            r'\\bMiss\\.?\\b': '<YoungFemale>',\n",
    "        }\n",
    "\n",
    "        self.korean_title_map = {\n",
    "            r'\\b의사\\s*선생님\\b': '<Doctor>',\n",
    "            r'\\b의사\\b': '<Doctor>',\n",
    "            r'\\b교수님\\b': '<Professor>',\n",
    "            r'\\b간호사\\b': '<Nurse>',\n",
    "            r'\\b상담사\\b': '<Counselor>',\n",
    "            r'\\b오빠\\b': '<OlderBrother>',\n",
    "            r'\\b형\\b': '<OlderBrother>',\n",
    "            r'\\b언니\\b': '<OlderSister>',\n",
    "            r'\\b누나\\b': '<OlderSister>',\n",
    "            r'\\b아저씨\\b': '<Mister>',\n",
    "            r'\\b아줌마\\b': '<Madam>',\n",
    "            r'\\b사장님\\b': '<Boss>',\n",
    "            r'\\b손님\\b': '<Customer>',\n",
    "            r'\\b환자\\b': '<Patient>',\n",
    "            r'\\b기사님\\b': '<Driver>',\n",
    "        }\n",
    "\n",
    "        # split markers는 유지하되 강제 split 정도만 조정\n",
    "        self.split_markers = [\n",
    "            \"그리고\", \"근데\", \"그런데\", \"하지만\",\n",
    "            \"그러나\", \"그래서\", \"그러니까\",\n",
    "            \"또\", \"또한\", \"게다가\",\n",
    "        ]\n",
    "\n",
    "\n",
    "    # ====================================================\n",
    "    # Speaker Tag\n",
    "    # ====================================================\n",
    "    def normalize_speaker(self, text):\n",
    "        text = re.sub(r'#Person1#\\s*:?', '<speaker1> ', text)\n",
    "        text = re.sub(r'#Person2#\\s*:?', '<speaker2> ', text)\n",
    "        text = re.sub(r'#Person3#\\s*:?', '<speaker3> ', text)\n",
    "        return text\n",
    "\n",
    "\n",
    "    # ====================================================\n",
    "    # 따옴표 정규화\n",
    "    # ====================================================\n",
    "    def normalize_quotes(self, text):\n",
    "        quote_map = {\n",
    "            \"“\": '\"', \"”\": '\"',\n",
    "            \"‘\": \"'\", \"’\": \"'\",\n",
    "            \"「\": '\"', \"」\": '\"',\n",
    "            \"『\": '\"', \"』\": '\"',\n",
    "            \"‹\": \"'\", \"›\": \"'\",\n",
    "            \"«\": '\"', \"»\": '\"',\n",
    "        }\n",
    "        for k, v in quote_map.items():\n",
    "            text = text.replace(k, v)\n",
    "        return text\n",
    "\n",
    "\n",
    "    # ====================================================\n",
    "    # 영어/한국어 호칭 변환\n",
    "    # ====================================================\n",
    "    def normalize_titles(self, text):\n",
    "        for pat, token in self.title_map.items():\n",
    "            text = re.sub(\n",
    "                pat + r'\\s+([A-Z][a-zA-Z]+)',\n",
    "                lambda m: f\"{token} {m.group(1)}\",\n",
    "                text, flags=re.IGNORECASE\n",
    "            )\n",
    "        for pat, token in self.korean_title_map.items():\n",
    "            text = re.sub(pat, token, text)\n",
    "        return text\n",
    "\n",
    "\n",
    "    # ====================================================\n",
    "    # 숫자/돈/엔터티 마스킹 삭제\n",
    "    #  → ROUGE 최적화에서는 그대로 두는 것이 유리\n",
    "    # ====================================================\n",
    "    def pass_numbers(self, text):\n",
    "        return text\n",
    "\n",
    "    def pass_named_entities(self, text):\n",
    "        return text\n",
    "\n",
    "\n",
    "    # ====================================================\n",
    "    # 욕설 마스킹도 제거 (ROUGE 목적)\n",
    "    # ====================================================\n",
    "    def pass_badwords(self, text):\n",
    "        return text\n",
    "\n",
    "\n",
    "    # ====================================================\n",
    "    # 문장 끝 정비 — 최소한만 유지\n",
    "    # ====================================================\n",
    "    def split_by_conjunction(self, text):\n",
    "        # 마지막에 .?! 없으면 . 하나만 추가\n",
    "        if not re.search(r'[.?!]\\s*$', text):\n",
    "            text = text + '.'\n",
    "        return text\n",
    "\n",
    "\n",
    "    # ====================================================\n",
    "    # 영어 문장 끝 처리 — 오류 패치 적용\n",
    "    # ====================================================\n",
    "    def english_sentence_end(self, text):\n",
    "        if re.search(r'[.?!]\\s*$', text):\n",
    "            return text\n",
    "        return re.sub(r'([A-Za-z]+)$', r'\\1.', text)\n",
    "\n",
    "\n",
    "    # ====================================================\n",
    "    # 한자/특수문자 노이즈 제거\n",
    "    # ====================================================\n",
    "    def clean_hanja_noise(self, text):\n",
    "        text = re.sub(r\"[『』《》]\", \"\", text)\n",
    "        text = re.sub(r\"[─━│┃╭╮╰╯]\", \"\", text)\n",
    "        return text\n",
    "\n",
    "\n",
    "    # ====================================================\n",
    "    # 전체 파이프라인\n",
    "    # ====================================================\n",
    "    def run(self, text):\n",
    "        if not isinstance(text, str):\n",
    "            return \"\"\n",
    "\n",
    "        text = self.normalize_speaker(text)\n",
    "        text = self.normalize_quotes(text)\n",
    "        text = self.normalize_titles(text)\n",
    "\n",
    "        # masking 계열 모두 제거 (ROUGE 최적화)\n",
    "        text = self.pass_numbers(text)\n",
    "        text = self.pass_named_entities(text)\n",
    "        text = self.pass_badwords(text)\n",
    "\n",
    "        text = self.clean_hanja_noise(text)\n",
    "        text = self.split_by_conjunction(text)\n",
    "        text = self.english_sentence_end(text)\n",
    "\n",
    "        return text\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 실행\n",
    "# ============================================================\n",
    "print(\"\\nLoading raw CSV...\")\n",
    "train_df = pd.read_csv(RAW_DIR / \"train.csv\")\n",
    "test_df  = pd.read_csv(RAW_DIR / \"test.csv\")\n",
    "\n",
    "pre = DialoguePreprocessor()\n",
    "\n",
    "print(\"\\nProcessing TRAIN...\")\n",
    "train_df[\"dialogue_clean\"] = train_df[\"dialogue\"].apply(lambda x: pre.run(str(x)))\n",
    "\n",
    "print(\"Processing TEST...\")\n",
    "test_df[\"dialogue_clean\"] = test_df[\"dialogue\"].apply(lambda x: pre.run(str(x)))\n",
    "\n",
    "train_out = PROCESSED_DIR / \"v1_train_preprocessed.csv\"\n",
    "test_out  = PROCESSED_DIR / \"v1_test_preprocessed.csv\"\n",
    "\n",
    "train_df.to_csv(train_out, index=False)\n",
    "test_df.to_csv(test_out, index=False)\n",
    "\n",
    "print(\"\\nSAVED:\")\n",
    "print(train_out)\n",
    "print(test_out)\n",
    "print(\"\\nDONE.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea9bb32-6654-4cd4-b486-7ce19c3b4a74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py310)",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
